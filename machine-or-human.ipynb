{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"In 2015 the idea of creating a computer system that could recognise human was considered so outrageously challenging that it was the basis of this XKCD joke:In 2015 the idea of creating a computer system that could recognise humans was considered so outrageously challenging that it was the basis of this XKCD joke","metadata":{}},{"cell_type":"markdown","source":"But today, we can do exactly that, in just a few minutes, using entirely free resources!\n\nThe basic steps we'll take are:\n\nUse DuckDuckGo to search for images of \"Human Potraits\"\nUse DuckDuckGo to search for images of \"Robots photos\"\nFine-tune a pretrained neural network to recognise these two groups\nTry running this model on a picture of a human and see if it works.","metadata":{}},{"cell_type":"code","source":"import os\niskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\n\nif iskaggle:\n    !pip install -Uqq fastai 'duckduckgo_search>=6.2'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install ddgs","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from ddgs import DDGS\nfrom fastcore.all import *\n\ndef search_images(keywords,max_images=200):return L(DDGS().images(keywords,max_results=max_images)).itemgot('image')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"urls=search_images('human potrait photos',max_images=5)\nurls","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from fastdownload import download_url\nfrom fastai.vision.all import *\nimport matplotlib.pyplot as plt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def show_thumbnails(urls):\n    \n    fig, axes = plt.subplots(1, len(urls), figsize=(15, 3))\n    \n    for idx, url in enumerate(urls):\n        dest = f'image_{idx}.jpg'\n        download_url(url, dest, show_progress=False)\n        \n        im = Image.open(dest)\n        thumb = im.to_thumb(256, 256)\n        \n        axes[idx].imshow(thumb)\n        axes[idx].axis('off')\n        axes[idx].set_title(f'Image {idx+1}')\n    \n    plt.tight_layout()\n    # Remove plt.show() - Jupyter will display automatically","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"show_thumbnails(urls)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"urls=search_images('robots photos',max_images=5)\nurls","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"show_thumbnails(urls)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"searches = 'human potraits','robots'\npath = Path('human_or_not')\n\nfor o in searches:\n    dest = (path/o)\n    dest.mkdir(exist_ok=True, parents=True)\n    download_images(dest, urls=search_images(f'{o} photo'))\n    time.sleep(5)\n    resize_images(path/o, max_size=400, dest=path/o)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"failed = verify_images(get_image_files(path))\nfailed.map(Path.unlink)\nlen(failed)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dls = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=[Resize(192, method='squish')]\n).dataloaders(path, bs=32)\n\ndls.show_batch(max_n=6)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Here what each of the DataBlock parameters means:\n\nblocks=(ImageBlock, CategoryBlock),\nThe inputs to our model are images, and the outputs are categories (in this case, \"human potraits\" or \"robots\").\n\nget_items=get_image_files, \nTo find all the inputs to our model, run the get_image_files function (which returns a list of all image files in a path).\n\nsplitter=RandomSplitter(valid_pct=0.2, seed=42),\nSplit the data into training and validation sets randomly, using 20% of the data for the validation set.\n\nget_y=parent_label,\nThe labels (y values) is the name of the parent of each file (i.e. the name of the folder they're in, which will be human potraits or tobot).\n\nitem_tfms=[Resize(192, method='squish')]\nBefore training, resize each image to 192x192 pixels by \"squishing\" it (as opposed to cropping it).","metadata":{}},{"cell_type":"code","source":"learn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(3)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"is_human,_,probs = learn.predict(PILImage.create('human_1.jpg'))\nprint(f\"This is : {is_human}.\")\nprint(f\"Probability it's a human: {probs[0]:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"So, as you see, in the space of a few years, creating computer vision classification models has gone from \"so hard it's a joke\" to \"trivially easy and free\"!","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}